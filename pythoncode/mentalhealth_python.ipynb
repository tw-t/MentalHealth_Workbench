{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mental Health Prediction Using Machine Learning\n",
    "\n",
    "The 2024 Kaggle Playground Series aims to provide engaging and practical datasets for machine learning enthusiasts to enhance their skills. This project focuses on Mental Health Prediction, using data from a mental health survey to analyze the factors that contribute to depression. The goal is to build a predictive model that determines whether an individual is experiencing depression based on various factors present in the dataset.\n",
    "\n",
    "The dataset contains missing values, requiring preprocessing techniques such as data imputation and visualization for better insights. Various data analysis techniques, including count plots, pie charts, and heatmaps, will be used to understand the key contributing factors to depression.\n",
    "\n",
    "## Project Objectives\n",
    "\n",
    "The main objectives of this project are:\n",
    "\n",
    "- Understand the Dataset – Perform an in-depth exploration of the provided training, testing, sample submission, and original data to gain insights into its structure and attributes.\n",
    "- Handle Missing Values – Identify and impute missing values to ensure data quality and improve model performance.\n",
    "- Data Visualization & Analysis – Generate multiple visualization plots (count plots, pie charts, heatmaps, etc.) to analyze key factors affecting mental health and depression.\n",
    "- Model Implementation – Utilize the CatBoost model with optimized parameters to predict depression based on survey responses.\n",
    "- Enhance Model Performance – Implement Repeated Stratified K-Fold Cross-Validation to refine predictions and improve the reliability of the model.\n",
    "- Evaluate Results – Measure the model’s accuracy and effectiveness in classifying individuals with or without depression based on survey responses.\n",
    "\n",
    "## Project Scope\n",
    "\n",
    "<b>In-Scope:</b>\n",
    "\n",
    "- Dataset Exploration – Understanding the data, missing values, and feature distributions.\n",
    "- Data Preprocessing – Cleaning the dataset, handling missing values, and preparing it for modeling.\n",
    "- Feature Engineering – Creating meaningful features from the dataset to enhance predictions.\n",
    "- Data Visualization – Using plots and statistical analysis to explore depression risk factors.\n",
    "- Model Selection & Implementation – Implementing different models for prediction.\n",
    "- Performance Improvement – Using Repeated Stratified K-Fold for better accuracy. <b>MIGHT BE REVISED</B>\n",
    "- Prediction & Insights – Determining whether a person is at risk of depression based on analyzed factors.\n",
    "\n",
    "<b>Out-of-Scope:</b>\n",
    "\n",
    "- Medical Diagnosis – The project does not provide a medical diagnosis but rather a statistical analysis and prediction.\n",
    "- Real-time Monitoring – The model will not be deployed for real-time monitoring of mental health conditions.\n",
    "- Therapeutic Interventions – The project does not propose medical or psychological treatment solutions.\n",
    "\n",
    "## Data Source\n",
    "\n",
    "The dataset used in this project originates from the 2024 Kaggle Playground Series (Season 4, Episode 11) competition, titled \"<a href=\"https://www.kaggle.com/competitions/playground-series-s4e11/overview\">Exploring Mental Health Data</a>\". The data was derived from the <a href=\"https://www.kaggle.com/datasets/sumansharmadataworld/depression-surveydataset-for-analysis\">Depression Survey/Dataset</a> and has been augmented with synthetic data to increase its size.\n",
    "\n",
    "The dataset consists of 234,500 observations, with a 6:4 train-test split. It contains 20 features, each representing different attributes related to an individual's mental health and well-being. The target variable, \"Depression,\" is a binary flag (0 or 1) indicating whether an individual is experiencing depression.\n",
    "\n",
    "<b>Understanding the Features</b>\n",
    "\n",
    "<table border=\"1\">\n",
    "  <tr>\n",
    "    <th><b>Column Name</b></th>\n",
    "    <th><b>Description</b></th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>ID</td>\n",
    "    <td>Unique identifier for each participant in the dataset</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Name</td>\n",
    "    <td>Name of the participant</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Gender</td>\n",
    "    <td>Gender of participant (listed as Male or Female)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Age</td>\n",
    "    <td>Age of the participant</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>City</td>\n",
    "    <td>The city that the participant resides</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Working Professional or Student</td>\n",
    "    <td>Indicates whether the participant is a working professional or a student</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Profession</td>\n",
    "    <td>Participant's profession or field of study</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Academic Pressure</td>\n",
    "    <td>Level of pressure the participant's experiences in academics (on a scale of 1-5)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Work Pressure</td>\n",
    "    <td>Level of pressure the participant's experiences at their job (on a scale of 1-5)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>CGPA</td>\n",
    "    <td>Cumulative Grade Point Average of the participant</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Study Satisfaction</td>\n",
    "    <td>The participant's satisfaction with their studies (on a scale of 1-5)</td>\n",
    "  </tr>\n",
    "    </tr>\n",
    "    <tr>\n",
    "    <td>Job Satisfaction</td>\n",
    "    <td>The participant's satisfaction with their jobs (on a scale of 1-5)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sleep Duration</td>\n",
    "    <td>Average duration of sleep per night</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Dietary Habits</td>\n",
    "    <td>Dietary habits of the participant (listed mainly as healthy, moderate and unhealthy)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Degree</td>\n",
    "    <td>Level of education the participant is pursuing or has completed</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Have you ever had suicidal thoughts?</td>\n",
    "    <td>Indicates whether the participant has ever had suicidal thoughts (listed as yes or no)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Work/Study Hours</td>\n",
    "    <td>Number of hours the participant spends working or studying per day on average</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Financial Stress</td>\n",
    "    <td>Level of financial stress the participant experiences (on a scale of 1-5)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Family History of Mental Illness</td>\n",
    "    <td>Indicates whether the participant has a family history of mental illness (listed as yes or no)</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Depression</td>\n",
    "    <td>The participant's depression status (listed as 0 or 1)</td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Environment Set-Up and Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data import\n",
    "train = pd.read_csv(\"/workspaces/myfolder/MentalHealth_Workbench/data/train.csv\")\n",
    "test = pd.read_csv(\"/workspaces/myfolder/MentalHealth_Workbench/data/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Exploratory Data Analysis\n",
    "\n",
    "Exploratory data analysis (EDA) is crucial in data science projects because it helps us understand the structure and characteristics of the data we're working with. By exploring variables, identifying patterns, detecting anomalies, and visualizing relationships, EDA enables us to make informed decisions about data preprocessing, feature engineering, and model selection. It also plays a key role in uncovering insights and formulating hypotheses, laying the groundwork for more accurate modeling and impactful conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Data Transformation/Wrangling\n",
    "\n",
    "Data wrangling is essential in the model creation cycle as it ensures data quality, prepares data for modeling techniques, uncovers insights, and supports reproducibility. It forms the foundation upon which accurate, reliable, and actionable models can be derived from data in the field of data science. These steps are done based on what our exploratory data analysis (EDA) uncovered. In this case, we will be imputing our missing variables, encoding our categorical variables, and splitting our dataset for testing and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Modelling\n",
    "\n",
    "Modeling in the data science process involves the application of machine learning algorithms to analyze data, make predictions, or uncover patterns. It is a pivotal phase where the insights gleaned from data are translated into actionable decisions and solutions.\n",
    "\n",
    "Machine learning models are employed to address various tasks, such as classification, regression, clustering, and recommendation systems, depending on the nature of the problem at hand. These models learn from historical data to generalize patterns and make predictions on new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Model Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Evaluation and Selection\n",
    "\n",
    "Model evaluation and comparison are indispensable in the data science process as they validate the effectiveness and reliability of predictive models. By systematically evaluating models against relevant metrics such as accuracy, precision, recall, and F1-score, data scientists can assess which models perform best for specific tasks and datasets. This process not only ensures the chosen model meets desired performance criteria but also identifies potential weaknesses or biases that could impact its real-world application. Moreover, comparing different models allows data scientists to make informed decisions, selecting the most suitable model that balances accuracy, interpretability, and computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Registration and Deployment\n",
    "\n",
    "Models built on Workbench, whether they are scikit-learn models or SAS Viya ML models can be registered into the model repository on Viya (SAS Model Manager). This is a crucial step in ensuring that models can be goverened properly as corporate assets before being pushed into production.\n",
    "\n",
    "Let's look at examples of how to register a SAS Viya ML model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Work"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
